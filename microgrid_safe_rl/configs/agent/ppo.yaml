algo: ppo
ppo:
  policy: MlpPolicy
  learning_rate: 3.0e-4
  gamma: 0.995
  n_steps: 256        # per-env â†’ total rollout = n_steps * n_envs = 256*8=2048
  batch_size: 2048    # must divide total rollout
  n_epochs: 10
  gae_lambda: 0.95
  ent_coef: 0.0
  vf_coef: 0.5
  max_grad_norm: 0.5
  policy_kwargs:
    net_arch: [256, 256]
    activation_fn: relu
