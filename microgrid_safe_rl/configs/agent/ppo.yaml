# configs/agent/ppo.yaml
algo: ppo
params:
  n_steps: 2048
  batch_size: 256
  gamma: 0.95
  ent_coef: 0.03
  learning_rate: 3.0e-4
  n_epochs: 10
